{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7118f4f4",
   "metadata": {},
   "source": [
    "### Description\n",
    "This notebook will generate dataset for binary classification if the image is a traffic sign or not. Classes:\n",
    "- 0: traffic sign\n",
    "- 1: not traffic sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a9dd11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os, random\n",
    "import glob\n",
    "import cv2\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f241e7a",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f2fe857",
   "metadata": {},
   "outputs": [],
   "source": [
    "destiny_labels_dir = 'E:\\\\Data\\\\Traffic_Signs_Preprocessed_Bin\\\\labels.pickle'\n",
    "destiny_data_dir = 'E:\\\\Data\\\\Traffic_Signs_Preprocessed_Bin\\\\data.pickle'\n",
    "source_sign_data_dir = 'E:\\\\Data\\\\Traffic_Signs_Preprocessed_Class\\\\data.pickle' #\n",
    "source_data_dir = 'E:\\\\Data\\\\Crop_Images'  # images names should follow the following pattern 'image (NUMBER).jpg'\n",
    "source_data_count = 100 #\n",
    "gen_data_count = 104010 #\n",
    "img_rows = 32\n",
    "img_cols = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a76fe5",
   "metadata": {},
   "source": [
    "### Preparing env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b701b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read & preprocess data to crop images from\n",
    "#images = [cv2.cvtColor(cv2.imread(f\"{source_data_dir}\\\\image ({index}).jpg\", cv2.IMREAD_COLOR), cv2.COLOR_BGR2RGB) for index in range(1, source_data_count+1)]\n",
    "\n",
    "# read data with 43 classes\n",
    "signs_data = pd.read_pickle(source_sign_data_dir)\n",
    "x_train = np.flip(np.rot90(signs_data['x_train'].transpose(0, 3, 2, 1), axes=(1, 2)), axis=1).astype('float64')\n",
    "x_test = np.flip(np.rot90(signs_data['x_test'].transpose(0, 3, 2, 1), axes=(1, 2)), axis=1).astype('float64')\n",
    "x_valid = np.flip(np.rot90(signs_data['x_validation'].transpose(0, 3, 2, 1), axes=(1, 2)), axis=1).astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2495e08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(img):\n",
    "    return np.array(img, dtype='float64') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632312b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(images, destiny_shape=(img_rows, img_cols), count=gen_data_count):\n",
    "    images_count = len(images)\n",
    "    per_image_windows = int(count / images_count)\n",
    "    result = []\n",
    "    \n",
    "    for index, image in enumerate(images):\n",
    "        print(f\"Progress: {index+1}/{images_count}\")\n",
    "        preprocessed_image = preprocess_img(image)\n",
    "        \n",
    "        iterations = per_image_windows\n",
    "        if index == images_count-1:\n",
    "            iterations = count - len(result)\n",
    "            \n",
    "        for i in range(iterations):\n",
    "            scale = random.randint(5, 60)/100.0\n",
    "            min_dim = min(preprocessed_image.shape[0], preprocessed_image.shape[1])\n",
    "            dim = (int(min_dim*scale), int(min_dim*scale))\n",
    "            \n",
    "            x = random.randint(0, image.shape[1] - dim[1])\n",
    "            y = random.randint(0, image.shape[0] - dim[0])\n",
    "            \n",
    "            cropped = image[y:y+dim[0], x:x+dim[1]]\n",
    "            cropped = cv2.resize(cropped, destiny_shape)\n",
    "            result.append(cropped)\n",
    "            \n",
    "    return np.array(result, dtype='float64') / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52a2d30",
   "metadata": {},
   "source": [
    "### Generating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6307de6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generated_data = generate_data(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482713ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('E:\\\\Data\\\\Traffic_Signs_Preprocessed_Bin\\\\generated.pickle', 'wb') as handle:\n",
    "    pickle.dump(generated_data, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375f41f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_data = pd.read_pickle(source_sign_data_dir)\n",
    "signs_data = pd.read_pickle(source_sign_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fade979",
   "metadata": {},
   "outputs": [],
   "source": [
    "signs_data = np.concatenate((x_train, x_test, x_valid))\n",
    "signs_data = signs_data[:gen_data_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f7ac4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('E:\\\\Data\\\\Traffic_Signs_Preprocessed_Bin\\\\signs.pickle', 'wb') as handle:\n",
    "    pickle.dump(signs_data, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064f2269",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_data = pd.read_pickle('E:\\\\Data\\\\Traffic_Signs_Preprocessed_Bin\\\\generated.pickle')\n",
    "signs_data = pd.read_pickle('E:\\\\Data\\\\Traffic_Signs_Preprocessed_Bin\\\\signs.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d70d8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sign_data = np.zeros(gen_data_count)\n",
    "y_not_sign_data = np.ones(gen_data_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7fe3f3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"traffic sign\", \"not traffic sign\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0925ec24",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(destiny_labels_dir, 'wb') as handle:\n",
    "    pickle.dump(labels, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc39ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.concatenate((signs_data, generated_data))\n",
    "y_data = np.concatenate((y_sign_data, y_not_sign_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db1fd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('E:\\\\Data\\\\Traffic_Signs_Preprocessed_Bin\\\\x_data.pickle', 'wb') as handle:\n",
    "    pickle.dump(x_data, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e373d7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('E:\\\\Data\\\\Traffic_Signs_Preprocessed_Bin\\\\y_data.pickle', 'wb') as handle:\n",
    "    pickle.dump(y_data, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7c2c560",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = pd.read_pickle('E:\\\\Data\\\\Traffic_Signs_Preprocessed_Bin\\\\x_data.pickle')\n",
    "y_data = pd.read_pickle('E:\\\\Data\\\\Traffic_Signs_Preprocessed_Bin\\\\y_data.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1fb3de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "477eba54",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99511bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(177857, 32, 32, 3)\n",
      "(177857,)\n",
      "(20802, 32, 32, 3)\n",
      "(20802,)\n",
      "(9361, 32, 32, 3)\n",
      "(9361,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(x_valid.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7fff7355",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"x_train\": x_train,\n",
    "    \"y_train\": y_train,\n",
    "    \"x_test\": x_test,\n",
    "    \"y_test\": y_test,\n",
    "    \"x_valid\": x_valid,\n",
    "    \"y_valid\": y_valid,\n",
    "    \"labels\": labels,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d951b968",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(destiny_data_dir, 'wb') as handle:\n",
    "    pickle.dump(data, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083b6830",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
